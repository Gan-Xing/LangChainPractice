{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb0f5f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jq\n",
      "  Using cached jq-1.4.1-cp311-cp311-macosx_10_9_x86_64.whl (363 kB)\n",
      "Installing collected packages: jq\n",
      "Successfully installed jq-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install jq\n",
    "from langchain.document_loaders import JSONLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "file_path='./chatgpt.json'\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.chains.question_answering import load_qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f89a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ChatGPT': {'免费开源': {'应用拓展': {'审计和报错': {'让我们在使用ChatGPT过程中更高效、更顺畅，完美解决ChatGPT网络错误，不再频繁地刷新网页，足足省去10个多余的步骤。还可以取消后台监管审计。解决了这几类报错：(1)尝试……时的网络错误': 'https://github.com/xcanwin/KeepChatGPT'}},\n",
      "                      '开发工具': {'代理': {'Cloudflare Worker / Vercel Edge 上的 OpenAI 代理': 'https://github.com/egoist/openai-proxy'},\n",
      "                               '代码管理': {'Hugging Face': 'https://huggingface.co/'},\n",
      "                               '大语言模型': {'Bard': '一个由EleutherAI社区创建的开源自然语言处理项目，旨在推动自然语言处理领域的研究和开发。该项目的目标是构建一个大型、高质量的预训练语言模型，以提高自然语言理解和生成的性能和效果。Bard项目的开发基于最新的自然语言处理技术和算法，并采用了分布式计算和开源协作的模式，以提高模型的训练效率和模型性能。Bard的开源代码和模型都可以在GitHub上找到，并且可以由开发者和研究者用于各种自然语言处理任务，如文本分类、问答、命名实体识别等。',\n",
      "                                         'ChatGPT': '最流行前沿',\n",
      "                                         'Hugging Face Hub': '一个在线模型和数据集平台，由Hugging '\n",
      "                                                             'Face创建和维护。它允许开发者和研究者共享、发现和使用预训练的自然语言处理模型和相关数据集，从而加速模型开发和研究。Hugging '\n",
      "                                                             'Face '\n",
      "                                                             'Hub上的模型和数据集都是由社区中的成员提供和维护的，包括研究人员、工程师和爱好者。通过Hugging '\n",
      "                                                             'Face '\n",
      "                                                             'Hub，开发者可以轻松地下载和使用各种类型的预训练模型，如BERT、GPT、RoBERTa等，并用于各种自然语言处理任务，如文本分类、命名实体识别、问答等。',\n",
      "                                         'Langchain': '一个开源自然语言处理项目，旨在为语言研究和开发者提供一个通用的自然语言处理框架。该项目的目标是创建一个基于链式体系结构的通用自然语言处理系统，以提高自然语言理解和生成的性能和效果。langchain项目支持各种自然语言处理任务，如文本分类、命名实体识别、情感分析、机器翻译等。它还提供了一个易于使用的API和一些预训练的语言模型，以帮助开发者快速构建和部署自然语言处理应用。langchain是由一个开源社区开发和维护的，任何人都可以参与其中，并为项目做出贡献'},\n",
      "                               '官方API': {'OpenAI API': 'https://openai.com/blog/openai-api'},\n",
      "                               '官方指南': {'使用 OpenAI API 的示例和指南': 'https://github.com/openai/openai-cookbook'},\n",
      "                               '官方插件': {'ChatGPT 检索插件让您轻松通过提问在日常工作文档中搜索和查找信息。': 'https://github.com/openai/chatgpt-retrieval-plugin'},\n",
      "                               '嵌入生成器': {'Cohere嵌入API': 'https://docs.cohere.ai/reference/embed',\n",
      "                                         'GPTCache/paraphrase-albert-onnx模型的ONNX': 'https://onnx.ai/',\n",
      "                                         'Hugging Face嵌入（transformers，ViTModel，Data2VecAudio）': 'https://huggingface.co/',\n",
      "                                         'OpenAI嵌入API': 'https://openai.com/',\n",
      "                                         'SentenceTransformers嵌入': 'https://www.sbert.net/',\n",
      "                                         'Timm图像嵌入模型': 'https://timm.fast.ai/',\n",
      "                                         'fastText嵌入': 'https://fasttext.cc/'},\n",
      "                               '矢量存储': {'Faiss': ['用于高效相似性搜索和密集向量聚类的库。',\n",
      "                                                  'https://github.com/facebookresearch/faiss',\n",
      "                                                  'https://faiss.ai/'],\n",
      "                                        'Milvus': ['这是一个用于生产就绪 AI/LLM '\n",
      "                                                   '应用程序的开源矢量数据库。',\n",
      "                                                   'https://github.com/milvus-io/milvus',\n",
      "                                                   'https://milvus.io/'],\n",
      "                                        'Milvus Lite': ['这是一个轻量级的 Milvus '\n",
      "                                                        '版本，可以嵌入到您的 Python '\n",
      "                                                        '应用程序中。',\n",
      "                                                        'https://github.com/milvus-io/milvus-lite'],\n",
      "                                        'Pinecone': 'https://www.pinecone.io/',\n",
      "                                        'Qdrant': 'https://qdrant.tech/',\n",
      "                                        'Weaviate': 'https://weaviate.io/',\n",
      "                                        'Zilliz': ['支持基于 Milvus 的全托管云矢量数据库',\n",
      "                                                   '',\n",
      "                                                   'https://zilliz.com'],\n",
      "                                        'hnswlib': ['用于快速近似最近邻的仅有头文件的 '\n",
      "                                                    'C++/Python 库',\n",
      "                                                    'https://github.com/nmslib/hnswlib']},\n",
      "                               '索引': {'Python': {'LlamaIndex (GPT Index) 是一个提供中央接口以将您的 LLM 与外部数据连接起来的项目。': 'https://github.com/jerryjliu/llama_index'}},\n",
      "                               '缓存': {'Python': {'GPTCache 是一个用于创建语义缓存以存储来自 LLM 查询的响应的库。': 'https://github.com/zilliztech/gptcache'}},\n",
      "                               '缓存存储': {'Duckdb': 'https://duckdb.org/',\n",
      "                                        'ElasticSearch': 'https://www.elastic.co/elasticsearch/',\n",
      "                                        'HBase': 'https://hbase.apache.org/',\n",
      "                                        'MariaDB': 'https://mariadb.org/',\n",
      "                                        'Minio': 'https://min.io/',\n",
      "                                        'MongoDB': 'https://www.mongodb.com/',\n",
      "                                        'MySQL': 'https://www.mysql.com/',\n",
      "                                        'Oracle': 'https://www.oracle.com/database/',\n",
      "                                        'PostgreSQL': 'https://www.postgresql.org/',\n",
      "                                        'Redis': 'https://redis.io/',\n",
      "                                        'SQL Server': 'https://www.microsoft.com/en-us/sql-server/',\n",
      "                                        'SQLite': 'https://www.sqlite.org/'},\n",
      "                               '计算词汇': {'tiktokenizer': 'https://github.com/dqbd/tiktokenizer'},\n",
      "                               '语言模型训练工具': {'ChatLLaMA': {'Date': '2023/02',\n",
      "                                                          'Desc': 'ChatLLaMA是一个开源的语言模型训练工具，它可以用于构建类似于ChatGPT的对话生成模型。使用ChatLLaMA时，用户可以基于LLaMA模型进行微调，并使用强化学习（RLHF）来改进生成的对话内容。相比于原始的ChatGPT训练流程，ChatLLaMA的训练过程更加高效和快速。ChatLLaMA是一个由Nebuly '\n",
      "                                                                  'AI提供支持的开源项目，可以在GitHub上找到完整的实现代码。',\n",
      "                                                          'Links': 'https://github.com/nebuly-ai/nebuly/tree/main/optimization/chatllama'}}},\n",
      "                      '开发拓展': {'IP限制': {'OpenAI API 免费反向代理': 'https://github.com/PawanOsman/ChatGPT',\n",
      "                                        '使用Next.js实现一键部署ChatGPT私有代理': 'https://github.com/imyuanx/chatgpt-proxy',\n",
      "                                        '使用cloudflare 搭建免费的 OpenAI api代理 ，解决网络无法访问问题。支持 Stream 流式输出': 'https://github.com/x-dr/chatgptProxyAPI'},\n",
      "                               'SDKS': {'Dart': {'Dart 客户端，用于使用非官方的 ChatGPT API': 'https://github.com/MisterJimson/chatgpt_api_dart'},\n",
      "                                        'Go': {'Golang 客户端，用于访问 ChatGPT（GPT-3.5-turbo）官方 API。': 'https://github.com/AlmazDelDiablo/gpt3-5-turbo-go'},\n",
      "                                        'Java': {'ChatGPT Java SDK 支持流式输出。支持 OpenAI 官方所有接口。ChatGPT 的 Java 客户端。OpenAI GPT-3.5-Turb GPT-4 Api Client for Java': 'https://github.com/Grt1228/chatgpt-java',\n",
      "                                                 'ChatGPT Java SDK。支持 GPT3.5、 GPT4 API。开箱即用。': 'https://github.com/PlexPt/chatgpt-java'},\n",
      "                                        'Kotlins': {'ChatGPT Android 在 Compose 中使用 Stream Chat SDK 展示 OpenAI 的 ChatGPT。': 'https://github.com/skydoves/chatgpt-android'},\n",
      "                                        'NodeJS': {'官方 ChatGPT API 的 Node.js 客户端。': 'https://github.com/transitive-bullshit/chatgpt-api',\n",
      "                                                   '适用于 ChatGPT 和 Bing AI 的客户端实现。可作为 Node.js 模块、REST API 服务器和 CLI 应用程序。': 'https://github.com/waylaidwanderer/node-chatgpt-api'},\n",
      "                                        'Python': {'ChatGPT': 'https://github.com/EthanForAi/ChatGPT',\n",
      "                                                   'Python客户端用于非官方ChatGPT API，具有自动令牌再生、会话跟踪、代理支持等功能。': 'https://github.com/rawandahmad698/PyChatGPT',\n",
      "                                                   '逆向工程API': 'https://github.com/acheong08/ChatGPT'}},\n",
      "                               '平台嵌入': {'Chrome': {'ChatGPT Chrome 扩展。将 ChatGPT 集成到互联网上的每个文本框。': 'https://github.com/gragland/chatgpt-chrome-extension',\n",
      "                                                   'ChatGPT Extension 是一个非常简单的 Chrome 扩展程序（manifest v3），你可以在网页的任何地方访问 OpenAI 的 ChatGPT': 'https://github.com/kazuki-sf/ChatGPT_Extension',\n",
      "                                                   'WebChatGPT：一个在您的 ChatGPT 提示中添加网络搜索结果的浏览器扩展。': 'https://github.com/qunash/chatgpt-advanced',\n",
      "                                                   '一个Chrome浏览器扩展，将ChatGPT嵌入其中，作为一个无需手动操作的语音助手。': 'https://github.com/idosal/assistant-chat-gpt',\n",
      "                                                   '增强搜索引擎功能的 ChatGPT 浏览器扩展': 'https://github.com/wong2/chatgpt-google-extension',\n",
      "                                                   '多合一聊天机器人客户端': 'https://github.com/chathub-dev/chathub',\n",
      "                                                   '将 ChatGPT 深度整合到浏览器中，您需要的一切都在这里': 'https://github.com/josStorer/chatGPTBox',\n",
      "                                                   '用于将你的ChatGPT历史记录下载为PNG、PDF或可分享链接的Chrome扩展': 'https://github.com/liady/ChatGPT-pdf',\n",
      "                                                   '用您的声音与 ChatGPT AI 对话，并通过语音听取其答案': 'https://github.com/C-Nedelcu/talk-to-chatgpt',\n",
      "                                                   '由ChatGPT自己编写的ChatGPT工具箱。当前功能：1.绕过高负载禁止登录 2.关闭数据监管 3.链路维持（减少网络错误）4.API混合接入 5.会话导入导出 6.聊天记录下载': 'https://github.com/bigemon/ChatGPT-ToolBox',\n",
      "                                                   '轻松地与您的朋友分享 ChatGPT 对话的永久链接。': 'https://github.com/domeccleston/sharegpt'},\n",
      "                                        'DingDing': {'钉钉 & 🤖 GPT-3.5 让你的工作效率直接起飞 🚀 私聊群聊方式、单聊串聊模式、角色扮演、图片创作 🚀': 'https://github.com/ConnectAI-E/Dingtalk-OpenAI'},\n",
      "                                        'Discord': {'另一个让您将ChatGPT集成到Discord的代码库': 'https://github.com/TheExplainthis/ChatGPT-Discord-Bot',\n",
      "                                                    '让您将ChatGPT集成到Discord的代码仓库': 'https://github.com/Zero6992/chatGPT-discord-bot'},\n",
      "                                        'Feishu': {'open加持下的飞书机器人，不仅是文本对话，还包括图片生成..': 'https://github.com/key7men/openai-feishu-bot',\n",
      "                                                   '为飞书准备的ChatGPT机器人': 'https://github.com/bestony/ChatGPT-Feishu',\n",
      "                                                   '快速将 ChatGPT 接入飞书，基于 OpenAI 官方接口，作为私人工作助理或者企业员工助理': 'https://github.com/whatwewant/chatgpt-for-chatbot-feishu',\n",
      "                                                   '飞书 ×（GPT-3.5 + DALL·E + Whisper）= 飞一般的工作体验 🚀 语音对话、角色扮演、多话题讨论、图片创作、表格分析、文档导出 🚀': 'https://github.com/ConnectAI-E/Feishu-OpenAI'},\n",
      "                                        'Github': {'由ChatGPT驱动的代码审查机器人': 'https://github.com/anc95/ChatGPT-CodeReview',\n",
      "                                                   '让ChatGPT为您审核 Pull Request': 'https://github.com/kxxt/chatgpt-action'},\n",
      "                                        'JetBrains': {'这个项目是一个插件，支持在 JetBrains 系列 IDE 上运行 ChatGPT。': 'https://github.com/dromara/ChatGPT'},\n",
      "                                        'Kubernetes': {'一个用于Kubernetes问题的ChatGPT机器人': 'https://github.com/robusta-dev/kubernetes-chatgpt-bot'},\n",
      "                                        'Line': {'让您将ChatGPT集成到Line的代码库': 'https://github.com/TheExplainthis/ChatGPT-Line-Bot'},\n",
      "                                        'Logseq': {'一个在Logseq中使用GPT-3人工智能辅助笔记的插件': 'https://github.com/briansunter/logseq-plugin-gpt3-openai'},\n",
      "                                        'MicroSoft Teams': {'ChatGPT Teams Bot 应用程序，可让您在 Microsoft Teams 中与 ChatGPT 聊天': 'https://github.com/formulahendry/chatgpt-teams-bot'},\n",
      "                                        'Obsidian': {'Text generator是Obsidian的一个实用插件，它可以帮助你使用GPT-3（OpenAI）生成文本内容': 'https://github.com/nhaouari/obsidian-textgenerator-plugin'},\n",
      "                                        'Roam Research': {'根据当前块生成文本；使用DALL-E 2生成图像；改写句子': 'https://github.com/LayBacc/roam-ai'},\n",
      "                                        'Siri': {'使用ChatGPT API gpt-3.5-turbo和gpt-4模型的Siri快捷方式，支持连续对话，配置API…': 'https://github.com/Yue-Yang/ChatGPT-Siri',\n",
      "                                                 '使用个性化提示将文本分享到ChatGPT的苹果快捷方式': 'https://github.com/reorx/Share-to-ChatGPT-Shortcut'},\n",
      "                                        'Slack': {'一种由社区驱动的阅读和与 AI 机器人聊天的方式 - 由 chatGPT 提供支持。': 'https://github.com/madawei2699/myGPTReader'},\n",
      "                                        'Telegram': {'ChatGPT在Telegram机器人中的尝试': 'https://github.com/altryne/chatGPT-telegram-bot',\n",
      "                                                     '一个使用Python编写的与OpenAI官方ChatGPT API集成的Telegram机器人': 'https://github.com/n3d1117/chatgpt-telegram-bot',\n",
      "                                                     '在Cloudflare Workers上轻松部署自己的Telegram ChatGPT机器人': 'https://github.com/TBXark/ChatGPT-Telegram-Workers',\n",
      "                                                     '基于 Node.js 的 Telegram ChatGPT 机器人。支持无浏览器和基于浏览器的 API。': 'https://github.com/RainEggplant/chatgpt-telegram-bot',\n",
      "                                                     '用单个命令运行自己的GPTChat电报机器人！': 'https://github.com/m1guelpf/chatgpt-telegram'},\n",
      "                                        'Unity': {'将 ChatGPT 集成到 Unity 编辑器': 'https://github.com/keijiro/AICommand',\n",
      "                                                  '用于Unity的ChatGPT驱动的着色器生成器': 'https://github.com/keijiro/AIShader'},\n",
      "                                        'VSCode': {'允许您使用 ChatGPT 的 VSCode 扩展': 'https://github.com/mpociot/chatgpt-vscode',\n",
      "                                                   '非官方的 Visual Studio Code - OpenAI ChatGPT 集成': 'https://github.com/gencay/vscode-chatgpt'},\n",
      "                                        'Wechat': {'为个人微信接入ChatGPT': 'https://github.com/djun/wechatbot',\n",
      "                                                   '基于 ChatGPT 的微信聊天机器人，使用 OpenAI api 和 itchat 库。使用 ChatGPT 搭建微信聊天机器人，基于 GPT3.5/4.0 API 和 itchat 实…': 'https://github.com/zhayujie/chatgpt-on-wechat',\n",
      "                                                   '微信版 ChatGPT': 'https://github.com/AutumnWhj/ChatGPT-wechat-bot',\n",
      "                                                   '通过 Wechaty 在微信上使用 ChatGPT': 'https://github.com/fuergaosi233/wechat-chatgpt'},\n",
      "                                        'Whatsapp': {'ChatGPT + DALL-E + WhatsApp = AI 助手 🚀 🤖': 'https://github.com/karfly/chatgpt_telegram_bot',\n",
      "                                                     '让您将ChatGPT集成到Whatsapp的代码库': 'https://github.com/victorharry/zap-gpt'},\n",
      "                                        'Xiaomi': {'用小米 AI 扬声器玩 ChatGPT': 'https://github.com/yihong0618/xiaogpt'}},\n",
      "                               '应用': {'Android': {'一个使用GPT人工智能过滤广告、垃圾邮件和通知的安卓应用程序': 'https://github.com/deskbtm/nitmgpt'},\n",
      "                                      'Mac': {'与ChatGPT互动的LaunchBar操作': 'https://github.com/quinncomendant/ChipiChat.lbaction',\n",
      "                                              '划词工具栏-类似于ChatGPT校对扩展，但具有不同的提示和可下载的包': 'https://github.com/hirakujira/ChatGPT-Grammar-Check-PopClip-Extension',\n",
      "                                              '基于 ChatGPT API 的文本翻译、文本润色、语法纠错 Bob 插件，让我们一起迎接不需要巴别塔的新时代': 'https://github.com/yetone/bob-plugin-openai-translator',\n",
      "                                              '桌面端AI语言练习应用': 'https://github.com/liou666/polyglot',\n",
      "                                              '适用于 Mac 的 ChatGPT，在您的菜单栏中显示。': 'https://github.com/vincelwt/chatgpt-mac'},\n",
      "                                      'Multi': {'ChatGPT 桌面应用程序（Mac，Windows 和 Linux）': 'https://github.com/lencx/ChatGPT',\n",
      "                                                'Flutter ChatGPT': 'https://github.com/redevRx/chat_gpt_sdk',\n",
      "                                                '一个适用于 MacOS、Windows、Linux、Android、iOS 和浏览器的 ChatGPT C# 客户端。由 Avalonia UI 框架驱动。': 'https://github.com/wieslawsoltes/ChatGPT',\n",
      "                                                '使用ChatGPT-Desktop提高生产力 - 极速且超强大！': 'https://github.com/Synaptrix/ChatGPT-Desktop',\n",
      "                                                '基于 ChatGPT API 的划词翻译浏览器插件和跨平台桌面端应用 ': 'https://github.com/yetone/openai-translator',\n",
      "                                                '桌面端的终极副驾驶员。Chatbox 是支持 Windows 的 GPT-4 / GPT-3.5 (OpenAI API) 桌面应用程序...': 'https://github.com/Bin-Huang/chatbox',\n",
      "                                                '🚀 一键部署！真正的 AI 聊天机器人！支持ChatGPT、文心一言、Bing、Bard、ChatGLM、POE，多账号，人设调教，虚拟女仆、图片渲染、语音发送': 'https://github.com/lss233/chatgpt-mirai-qq-bot'},\n",
      "                                      'Terminal': {'CLI 中的人工智能助手。但它知道您的系统上有什么，可以帮助您完成工作。': 'https://github.com/manno/chatgpt-linux-assistant',\n",
      "                                                   'ChatGPT CLI是一个命令行工具，可以通过交互式或基于文件的方式进行会话，并具有上下文和情绪。': 'https://github.com/verdverm/chatgpt',\n",
      "                                                   'DoctorGPT 将 GPT 引入生产环境，用于应用程序日志错误诊断！': 'https://github.com/ingyamilmolinar/doctorgpt',\n",
      "                                                   'GPTerminator 提供了一种使用命令行界面与 OpenAI 的聊天完成和图像生成 API 进行交互的便捷方式。': 'https://github.com/AineeJames/ChatGPTerminator',\n",
      "                                                   'turbocommit是一个基于Rust语言编写的CLI工具，它使用OpenAI的 gpt-3.5-turbo 语言模型，按照约定的提交规范生成高质量的git提交信息。它易于使用，是一种成本效益高的方式来保持git提交历史记录的高质量，帮助开发人员保持工作进度': 'https://github.com/Sett17/turboCommit',\n",
      "                                                   '一个以 DX 优先和更工程化、轻量级、可定制化的标准输出格式Commitizen适配器和命令行工具。': 'https://github.com/Zhengqbbb/cz-git',\n",
      "                                                   '一个优雅的交互式ChatGPT命令行界面': 'https://github.com/j178/chatgpt',\n",
      "                                                   '一个使用了 AI 技术的智能生词本工具，特色功能：自动添加生词、读故事助记单词。': 'https://github.com/piglei/ai-vocabulary-builder',\n",
      "                                                   '一个使用人工智能为你编写Git提交信息的命令行工具。': 'https://github.com/Nutlope/aicommits',\n",
      "                                                   '一个支持Markdown的命令行接口工具，使用OpenAI的API密钥连接到ChatGPT。': 'https://github.com/efJerryYang/chatgpt-cli/',\n",
      "                                                   '人工智能基础设施即代码生成器。': 'https://github.com/gofireflyio/aiac',\n",
      "                                                   '从R语言访问ChatGPT的接口': 'https://github.com/jcrodriguez1989/chatgpt',\n",
      "                                                   '使用 Python 和 Shell 与 ChatGPT 和 GPT4 互动的 API。': 'https://github.com/mmabrouk/chatgpt-wrapper',\n",
      "                                                   '使用Golang编写的ChatGPT控制台客户端': 'https://github.com/kkdai/chatgpt',\n",
      "                                                   '使用人工智能翻译制作双语EPUB电子书。': 'https://github.com/yihong0618/bilingual_book_maker',\n",
      "                                                   '命名变得简单：只需一个命令即可提高代码的可读性': 'https://github.com/davidleitw/naming',\n",
      "                                                   '将自然语言转换为 shell 命令的 CLI': 'https://github.com/BuilderIO/ai-shell',\n",
      "                                                   '用于使用 Python 和 Shell 与 ChatGPT 和 GPT4 交互的 API。': 'https://github.com/mmabrouk/chatgpt-wrapper',\n",
      "                                                   '用于生成美观、信息丰富且结构良好的自述文件的自动化工具。由 OpenAI LLM 提供支持': 'https://github.com/eli64s/README-AI',\n",
      "                                                   '这个命令行工具允许你轻松地在命令行中使用chatGPT。你可以与它聊天、问问题、获取文本翻译。它还支持在终端中呈现Markdown。': 'https://github.com/yufeikang/ai-cli',\n",
      "                                                   \"这是一个'chatgpt'的应用项目，仅适用于桌面环境。\": 'https://github.com/AIGCT/EASYChatGPT',\n",
      "                                                   '这是一个CLI工具，利用OpenAI API来翻译基于JSON格式的本地化文件。': 'https://github.com/pandodao/i18n-cli',\n",
      "                                                   '这是一个使用 open AI 的 whisper API 和 chatGPT 自动生成字幕的存储库': 'https://github.com/rongjc/autosubtitle',\n",
      "                                                   '这是一个简单的Shell脚本，可以在终端中使用OpenAI的ChatGPT和DALL-E，无需使用Python或JS。': 'https://github.com/0xacx/chatGPT-shell-cli'},\n",
      "                                      'Web': {'图文交互': {'Python+Html': {'微软开源图文交互APP': 'https://github.com/microsoft/TaskMatrix'}},\n",
      "                                              '在线翻译': {'TS+React': {'基于OpenAi的翻译器': 'https://github.com/LanceMoe/openai-translator'}},\n",
      "                                              '搜索引擎': {'想要将您的（弹性）搜索变成像 Bing + ChatGPT 一样热门的东西吗？看看 Elasticsearch + GPT3 Answerer！我们的程序拦截 Elasticsearch 结果并将它们发送到 GPT3，以便为您的查询提供准确且相关的答案。另外，使用起来非常有趣！': 'https://github.com/hunkim/es-gpt'},\n",
      "                                              '文件交互': {'HTML+Python': {'利用Python和ChatGPT完成翻译。': 'https://github.com/Raychanan/ChatGPT-for-Translation',\n",
      "                                                                       '基于向量数据库与GPT3.5的通用本地知识库方案': 'https://github.com/GanymedeNil/document.ai'},\n",
      "                                                       'JS+Python+Flask': {'一款基于开源LLM技术的研究助手，允许您与研究论文进行对话': 'https://github.com/mukulpatnaik/researchgpt'},\n",
      "                                                       'Python': {'为GPT/GLM提供图形交互界面，特别优化论文阅读润色体验，模块化设计支持自定义快捷按钮&函数插件，支持代码块表格显示，Tex公式双显示，新增Python和C++项目剖析&自译解功能，PDF/LaTex论文翻译&总结功能，支持并行问询多种LLM模型，支持清华chatglm等本地模型': 'https://github.com/binary-husky/gpt_academic'},\n",
      "                                                       'TS': {'AI 搜索和聊天 Paul Graham 的所有文章。': 'https://github.com/mckaywrigley/paul-graham-gpt',\n",
      "                                                              '聊天简化器': 'https://github.com/zhengbangbo/chat-simplifier'},\n",
      "                                                       'TS+Python': {'用于文档搜索和帮助的 GPT 支持的聊天。': 'https://github.com/arc53/docsgpt'},\n",
      "                                                       'TS+Python+React': {'与你的文件对话': 'https://github.com/guangzhengli/ChatFiles'}},\n",
      "                                              '聊天交互': {'TS+Nextjs': {'ChatGPT Next Web': 'https://github.com/Yidadaa/ChatGPT-Next-Web'}},\n",
      "                                              '论文提效': {'利用ChatGPT对审稿人的提问进行回复': 'https://github.com/nishiwen1214/ChatReviewer',\n",
      "                                                       '利用ChatGPT对论文初稿进行润色、翻译等': 'https://github.com/binary-husky/chatgpt_academic',\n",
      "                                                       '利用ChatGPT对论文进行优缺点分析，提出改进建议': 'https://github.com/nishiwen1214/ChatReviewer',\n",
      "                                                       '利用百万arXiv论文元信息训练出来的论文题目生成模型，根据论文摘要生成合适题目': 'https://github.com/WangRongsheng/ChatGenTitle',\n",
      "                                                       '通过ChatGPT实现对论文进行总结，帮助科研人进行论文初筛': 'https://github.com/kaixindelele/ChatPaper'},\n",
      "                                              '音视频总结': {'TS+Nextjs': {'使用chatGPT来翻译你的字幕': 'https://github.com/cgsvv/AISubtitle',\n",
      "                                                                      '音视频内容AI一键总结：哔哩哔哩丨YouTube丨网页丨播客丨会议丨本地文件等 (原 BiliGPT 省流神器 & 课代表)': 'https://github.com/JimmyLv/BibiGPT'}}}},\n",
      "                               '行业拓展': {'AR': {'使用ChatGPT和自然语言创建增强现实体验。': 'https://github.com/trzy/ChatARKit'},\n",
      "                                        '代码类': {'与您的代码库进行交互': 'https://github.com/shobrook/adrenaline/',\n",
      "                                                '使用 AI 自动生成约定式 git 提交信息。': 'https://github.com/guanguans/ai-commit',\n",
      "                                                '使用ChatGPT来解释您的错误信息。': 'https://github.com/shobrook/stackexplain',\n",
      "                                                '基于ChatGPT的渗透测试结果生成器。': 'https://github.com/Stratus-Security/FinGen'},\n",
      "                                        '文本类': {'DeepWrite AI是在ChatGPT3的帮助下制作的，专门为生成具有最大清晰度的完美博客文章而准备的特定模型。这只是1.0版本，将会实现更多的改进。': 'https://github.com/simplysabir/AI-Writing-Assistant',\n",
      "                                                '一个简单的命令行界面，可以使用Gpt3从一个主题开始生成WordPress文章。': 'https://github.com/nicolaballotta/gpt3-wordpress-post-generator'},\n",
      "                                        '法律援助': {'AI 法律助手': 'https://github.com/lvwzhen/law-cn-ai'},\n",
      "                                        '演示类': {'使用ChatGPT（或其他后端）自动生成PPT，在一个单一的文件中完成所有操作。': 'https://github.com/williamfzc/chat-gpt-ppt'},\n",
      "                                        '语音交互': {'使用您的语音与ChatGPT进行对话，并让它回答您。': 'https://github.com/platelminto/chatgpt-conversation'}}},\n",
      "                      '开源竞品': {'AIChatBot': {'Bard': ['https://blog.google/technology/ai/bard-google-ai-search-updates/',\n",
      "                                                      \"Bard is Google's new AI \"\n",
      "                                                      'chatbot service that '\n",
      "                                                      'uses LaMDA, a language '\n",
      "                                                      'model that can generate '\n",
      "                                                      'natural and informative '\n",
      "                                                      'responses. Bard can '\n",
      "                                                      'help users with '\n",
      "                                                      'creative tasks, '\n",
      "                                                      'explaining complex '\n",
      "                                                      'topics, and learning '\n",
      "                                                      'new things. Bard is '\n",
      "                                                      \"Google's answer to \"\n",
      "                                                      \"ChatGPT, Microsoft's \"\n",
      "                                                      'popular AI chatbot.'],\n",
      "                                             'Character ai': ['https://beta.character.ai/',\n",
      "                                                              'Unlike ChatGPT, '\n",
      "                                                              'it categorizes '\n",
      "                                                              'the chatbots '\n",
      "                                                              'into various '\n",
      "                                                              'subfields. It '\n",
      "                                                              'allows people '\n",
      "                                                              'to participate '\n",
      "                                                              'in the creation '\n",
      "                                                              'process through '\n",
      "                                                              'a platform '\n",
      "                                                              'instead of '\n",
      "                                                              'solely relying '\n",
      "                                                              'on '\n",
      "                                                              'self-creation '\n",
      "                                                              'and model '\n",
      "                                                              'training.'],\n",
      "                                             'ChatGLM': ['https://chatglm.cn/blog?continueFlag=af5320e8f778b996afe7697670864685',\n",
      "                                                         'This is a '\n",
      "                                                         'multibillion '\n",
      "                                                         'Chinese-English '\n",
      "                                                         'language model with '\n",
      "                                                         'basic '\n",
      "                                                         'question-and-answer '\n",
      "                                                         'and conversational '\n",
      "                                                         'capabilities, '\n",
      "                                                         'optimized for '\n",
      "                                                         'Chinese language.'],\n",
      "                                             'Jasper Chat': ['https://www.jasper.ai/chat',\n",
      "                                                             'A feature in the '\n",
      "                                                             'Jasper AI '\n",
      "                                                             'ecosystem, '\n",
      "                                                             'unlike ChatGPT, '\n",
      "                                                             'it is a paid '\n",
      "                                                             'service.'],\n",
      "                                             'MOSS': ['https://moss.fastnlp.top/',\n",
      "                                                      'Can perform a series of '\n",
      "                                                      'tasks such as dialogue '\n",
      "                                                      'generation, '\n",
      "                                                      'programming, fact '\n",
      "                                                      'answering, etc.'],\n",
      "                                             'OpenChatKit': ['https://github.com/togethercomputer/OpenChatKit',\n",
      "                                                             'A toolkit '\n",
      "                                                             'similar to '\n",
      "                                                             'ChatGPT, based '\n",
      "                                                             \"on EleutherAI's \"\n",
      "                                                             'GPT-NeoX-20B, '\n",
      "                                                             'containing a '\n",
      "                                                             'large model with '\n",
      "                                                             '20 billion '\n",
      "                                                             'parameters that '\n",
      "                                                             'has been '\n",
      "                                                             'fine-tuned on 43 '\n",
      "                                                             'million '\n",
      "                                                             'prompts.'],\n",
      "                                             'Perplexity AI': ['https://www.perplexity.ai/',\n",
      "                                                               'AI, which at '\n",
      "                                                               'its core '\n",
      "                                                               'combines a '\n",
      "                                                               'large-scale '\n",
      "                                                               'language model '\n",
      "                                                               'with a search '\n",
      "                                                               'engine to '\n",
      "                                                               'perform Q&A, '\n",
      "                                                               'providing '\n",
      "                                                               'users with the '\n",
      "                                                               'answers they '\n",
      "                                                               'need in the '\n",
      "                                                               'form of a '\n",
      "                                                               'continuous '\n",
      "                                                               'dialogue. '\n",
      "                                                               'Compared to '\n",
      "                                                               'ChatGPT, '\n",
      "                                                               'Perplexity AI '\n",
      "                                                               'is able to '\n",
      "                                                               'provide '\n",
      "                                                               'sources of '\n",
      "                                                               'information , '\n",
      "                                                               'but the '\n",
      "                                                               'fluency and '\n",
      "                                                               'completeness '\n",
      "                                                               'of its answers '\n",
      "                                                               'is slightly '\n",
      "                                                               'less than '\n",
      "                                                               'ChatGPT.'],\n",
      "                                             'YouChat': ['https://you.com/search?q=who+are+you&tbm=youchat&cfr=chat',\n",
      "                                                         'YouChat is a chatbot '\n",
      "                                                         'from You.com, '\n",
      "                                                         'founded by language '\n",
      "                                                         'and artificial '\n",
      "                                                         'intelligence expert '\n",
      "                                                         'Richard Socher, a '\n",
      "                                                         'GPT-3-based text '\n",
      "                                                         'generator for '\n",
      "                                                         'writing emails and '\n",
      "                                                         'other documents. In '\n",
      "                                                         'contrast to ChatGPT, '\n",
      "                                                         \"YouChat's replies \"\n",
      "                                                         'are cited, which in '\n",
      "                                                         'turn helps users '\n",
      "                                                         'track the source of '\n",
      "                                                         'each message.'],\n",
      "                                             '澜舟认知智能平台': ['https://langboat.com/technology/mengzi',\n",
      "                                                          'Based on Mencius '\n",
      "                                                          'pre-training '\n",
      "                                                          'technology, unlock '\n",
      "                                                          'full-range AIGC '\n",
      "                                                          'capabilities such '\n",
      "                                                          'as text-image '\n",
      "                                                          'generation, '\n",
      "                                                          'literary assistance '\n",
      "                                                          'creation, marketing '\n",
      "                                                          'copywriting, paper '\n",
      "                                                          'assistance writing, '\n",
      "                                                          'etc.']},\n",
      "                               'EleutherAI': {'GPT-J-6B': {'Date': '2021/06',\n",
      "                                                           'Desc': 'GPT-J-6B是一个基于自回归模型的语言模型，与类似的GPT-3模型相比，GPT-J-6B在参数量上有着更大的优势，达到了6亿个左右的参数数量。GPT-J-6B的训练数据来自于英文维基百科和Common '\n",
      "                                                                   'Crawl等数据集，同时还使用了对抗训练等技术来提高模型的鲁棒性和泛化能力。',\n",
      "                                                           'Dev': {'Databricks': {'Dolly1.0': {'Date': '2023/03',\n",
      "                                                                                               'Desc': 'Dolly大语言模型是Databricks公司开源的一个基于GPT的自然语言处理模型，包括Dolly '\n",
      "                                                                                                       '1.0和Dolly '\n",
      "                                                                                                       '2.0等不同版本。其中，Dolly '\n",
      "                                                                                                       '2.0是最新的版本，于2023年4月发布。Dolly大语言模型采用了Databricks自主研发的其它技术，如instruction-following等。',\n",
      "                                                                                               'Lang': 'EN',\n",
      "                                                                                               'Links': 'https://github.com/databrickslabs/dolly',\n",
      "                                                                                               'Size': '12B'}}},\n",
      "                                                           'Lang': 'Multi',\n",
      "                                                           'Links': 'https://github.com/kingoflolz/mesh-transformer-jax',\n",
      "                                                           'Size': '0.6B'},\n",
      "                                              'GPT-NeoX-20B': {'Date': '2022/04',\n",
      "                                                               'Desc': 'GPT-NeoX是一个基础的自然语言处理模型，它采用了类似于GPT-3的3个阶段的预训练方法，具有多语言支持和强大的生成能力。 '\n",
      "                                                                       'GPT-NeoX目前是由EleutherAI社区开发的一个开源框架，在GitHub上提供了开放的预训练模型，以及适用于各种自然语言处理应用的相关教程和示例。',\n",
      "                                                               'Dev': {'Together&&LAION&&Ontocord.ai.': {'GPT-NeoXT-Chat-Base-20B': {'Date': '2023/03',\n",
      "                                                                                                                                     'Desc': 'GPT-NeoXT-Chat-Base-20B-v0.16 '\n",
      "                                                                                                                                             '基于 '\n",
      "                                                                                                                                             'ElutherAI '\n",
      "                                                                                                                                             '的 '\n",
      "                                                                                                                                             'GPT-NeoX '\n",
      "                                                                                                                                             '模型，并针对专注于对话式交互的数据进行了微调。我们将调整重点放在几个任务上，例如问答、分类、提取和摘要。我们使用 '\n",
      "                                                                                                                                             '4300 '\n",
      "                                                                                                                                             '万条高质量指令集对模型进行了微调。与 '\n",
      "                                                                                                                                             'LAION '\n",
      "                                                                                                                                             '和 '\n",
      "                                                                                                                                             'Ontocord.ai '\n",
      "                                                                                                                                             '合作，他们都帮助管理了模型所基于的数据集。',\n",
      "                                                                                                                                     'GPU': '48G',\n",
      "                                                                                                                                     'Lang': 'EN',\n",
      "                                                                                                                                     'Links': 'https://github.com/togethercomputer/OpenChatKit',\n",
      "                                                                                                                                     'Size': '20B'}}},\n",
      "                                                               'Lang': 'Multi',\n",
      "                                                               'Links': 'https://github.com/EleutherAI/pythia',\n",
      "                                                               'Size': '20B'},\n",
      "                                              'Pythia': {'Date': '2023/04',\n",
      "                                                         'Desc': 'Pythia '\n",
      "                                                                 'Scaling '\n",
      "                                                                 'Suite是一组为促进可解释性研究而开发的模型。它包含两组八个型号，尺寸分别为 '\n",
      "                                                                 '70M、160M、410M、1B、1.4B、2.8B、6.9B '\n",
      "                                                                 '和 '\n",
      "                                                                 '12B。对于每种尺寸，有两种模型：一种是在 '\n",
      "                                                                 'Pile '\n",
      "                                                                 '上训练的，另一种是在对数据集进行全局去重后在 '\n",
      "                                                                 'Pile 上训练的。所有 '\n",
      "                                                                 '8 '\n",
      "                                                                 '种模型尺寸都以完全相同的顺序在完全相同的数据上进行训练。我们还为每个模型提供 '\n",
      "                                                                 '154 '\n",
      "                                                                 '个中间检查点，作为分支托管在 '\n",
      "                                                                 'Hugging Face '\n",
      "                                                                 '上。Pythia '\n",
      "                                                                 '模型套件旨在促进大型语言模型的科学研究，尤其是可解释性研究。尽管没有将下游性能作为设计目标，但我们发现这些模型的性能达到或超过了类似和相同尺寸模型的性能，例如 '\n",
      "                                                                 'OPT 和 '\n",
      "                                                                 'GPT-Neo '\n",
      "                                                                 '套件中的模型。',\n",
      "                                                         'Dev': {'Databricks': {'Dolly2.0': {'Date': '2023/04',\n",
      "                                                                                             'Desc': 'Dolly大语言模型是Databricks公司开源的一个基于GPT的自然语言处理模型，包括Dolly '\n",
      "                                                                                                     '1.0和Dolly '\n",
      "                                                                                                     '2.0等不同版本。其中，Dolly '\n",
      "                                                                                                     '2.0是最新的版本，于2023年4月发布。Dolly大语言模型采用了Databricks自主研发的其它技术，如instruction-following等。',\n",
      "                                                                                             'Lang': 'EN',\n",
      "                                                                                             'Links': 'https://github.com/EleutherAI/gpt-neox',\n",
      "                                                                                             'Size': '12B'}}},\n",
      "                                                         'Lang': 'EN',\n",
      "                                                         'Links': 'https://github.com/EleutherAI/pythia',\n",
      "                                                         'Size': '12B'}},\n",
      "                               'Google': {'T5': {'Date': '2019/10',\n",
      "                                                 'Desc': 'T5 '\n",
      "                                                         '是谷歌提出了一个统一预训练模型和框架，模型采用了谷歌最原始的 '\n",
      "                                                         'Encoder-Decoder '\n",
      "                                                         'Transformer结构。T5将每个文本处理问题都看成“Text-to-Text”问题，即将文本作为输入，生成新的文本作为输出。通过这种方式可以将不同的 '\n",
      "                                                         'NLP '\n",
      "                                                         '任务统一在一个模型框架之下，充分进行迁移学习。为了告知模型需要执行的任务类型，在输入的文本前添加任务特定的文本前缀 '\n",
      "                                                         '(task-specific '\n",
      "                                                         'prefifix ) '\n",
      "                                                         '进行提示，这也就是最早的 '\n",
      "                                                         'Prompt。也就说可以用同样的模型，同样的损失函数，同样的训练过程，同样的解码过程来完成所有 '\n",
      "                                                         'NLP 任务。T5 '\n",
      "                                                         '本身主要是针对英文训练，谷歌还发布了支持 '\n",
      "                                                         '101 种语言的 T5 的多语言版本 '\n",
      "                                                         'mT5[2]。',\n",
      "                                                 'Dev': {},\n",
      "                                                 'Lang': 'EN',\n",
      "                                                 'Links': 'https://github.com/google-research/text-to-text-transfer-transformer',\n",
      "                                                 'Size': '13B'}},\n",
      "                               'Hugging Face': {'BLOOM': {'Date': '2022/07',\n",
      "                                                          'Desc': 'BLOOM is an '\n",
      "                                                                  'autoregressive '\n",
      "                                                                  'Large '\n",
      "                                                                  'Language '\n",
      "                                                                  'Model '\n",
      "                                                                  '(LLM), '\n",
      "                                                                  'trained to '\n",
      "                                                                  'continue '\n",
      "                                                                  'text from a '\n",
      "                                                                  'prompt on '\n",
      "                                                                  'vast '\n",
      "                                                                  'amounts of '\n",
      "                                                                  'text data '\n",
      "                                                                  'using '\n",
      "                                                                  'industrial-scale '\n",
      "                                                                  'computational '\n",
      "                                                                  'resources. '\n",
      "                                                                  'As such, it '\n",
      "                                                                  'is able to '\n",
      "                                                                  'output '\n",
      "                                                                  'coherent '\n",
      "                                                                  'text in 46 '\n",
      "                                                                  'languages '\n",
      "                                                                  'and 13 '\n",
      "                                                                  'programming '\n",
      "                                                                  'languages '\n",
      "                                                                  'that is '\n",
      "                                                                  'hardly '\n",
      "                                                                  'distinguishable '\n",
      "                                                                  'from text '\n",
      "                                                                  'written by '\n",
      "                                                                  'humans. '\n",
      "                                                                  'BLOOM can '\n",
      "                                                                  'also be '\n",
      "                                                                  'instructed '\n",
      "                                                                  'to perform '\n",
      "                                                                  'text tasks '\n",
      "                                                                  \"it hasn't \"\n",
      "                                                                  'been '\n",
      "                                                                  'explicitly '\n",
      "                                                                  'trained '\n",
      "                                                                  'for, by '\n",
      "                                                                  'casting '\n",
      "                                                                  'them as '\n",
      "                                                                  'text '\n",
      "                                                                  'generation '\n",
      "                                                                  'tasks.',\n",
      "                                                          'Dev': {'Hugging Face': {'BLOOMZ & mT0': {'Date': '2022/11',\n",
      "                                                                                                    'Desc': '上述 '\n",
      "                                                                                                            'T0 '\n",
      "                                                                                                            '和 '\n",
      "                                                                                                            'FLAN '\n",
      "                                                                                                            '等指令微调模型证明了多任务提示微调 '\n",
      "                                                                                                            '(MTF) '\n",
      "                                                                                                            '可以帮助大模型在 '\n",
      "                                                                                                            'zero-shot '\n",
      "                                                                                                            '条件下泛化到新任务，并且对 '\n",
      "                                                                                                            'MTF '\n",
      "                                                                                                            '的探索主要集中在英语数据和模型上。 '\n",
      "                                                                                                            'Hugging '\n",
      "                                                                                                            'Face '\n",
      "                                                                                                            '将 '\n",
      "                                                                                                            'MTF '\n",
      "                                                                                                            '应用于预训练的多语言 '\n",
      "                                                                                                            'BLOOM '\n",
      "                                                                                                            '和 '\n",
      "                                                                                                            'mT5 '\n",
      "                                                                                                            '模型系列，发布了称为 '\n",
      "                                                                                                            'BLOOMZ '\n",
      "                                                                                                            '和 '\n",
      "                                                                                                            'mT0 '\n",
      "                                                                                                            '的指令微调变体。研究实验中发现在具有英语提示的英语任务上微调多语言大模型可以将任务泛化到仅出现在预训练中的非英语任务；使用英语提示对多语言任务进行微调进一步提高了英语和非英语任务的性能，实现各种最先进的 '\n",
      "                                                                                                            'zero-shot '\n",
      "                                                                                                            '结果； '\n",
      "                                                                                                            '论文还研究了多语言任务的微调，这些任务使用从英语翻译的提示来匹配每个数据集的语言，实验发现翻译的提示可以提高相应语言的人工提示的性能。 '\n",
      "                                                                                                            '实验还发现模型能够对它们从未见过的语言任务进行零样本泛化，推测这些模型正在学习与任务和语言无关的更高级别的能力。',\n",
      "                                                                                                    'Links': 'https://huggingface.co/bigscience/bloomz'}}},\n",
      "                                                          'Lang': 'Multi',\n",
      "                                                          'Links': 'https://huggingface.co/bigscience/bloom',\n",
      "                                                          'Size': '176B'}},\n",
      "                               'LLMs': {'BLOOM': ['https://huggingface.co/bigscience/bloom',\n",
      "                                                  'by BigScience, BLOOM is an '\n",
      "                                                  'autoregressive Large '\n",
      "                                                  'Language Model (LLM), '\n",
      "                                                  'trained to continue text '\n",
      "                                                  'from a prompt on vast '\n",
      "                                                  'amounts of text data using '\n",
      "                                                  'industrial-scale '\n",
      "                                                  'computational resources. As '\n",
      "                                                  'such, it is able to output '\n",
      "                                                  'coherent text in 46 '\n",
      "                                                  'languages and 13 '\n",
      "                                                  'programming languages that '\n",
      "                                                  'is hardly distinguishable '\n",
      "                                                  'from text written by '\n",
      "                                                  'humans. BLOOM can also be '\n",
      "                                                  'instructed to perform text '\n",
      "                                                  \"tasks it hasn't been \"\n",
      "                                                  'explicitly trained for, by '\n",
      "                                                  'casting them as text '\n",
      "                                                  'generation tasks.'],\n",
      "                                        'GLM': ['https://github.com/THUDM/GLM-130B',\n",
      "                                                'GLM is a General Language '\n",
      "                                                'Model developed by Tsinghua '\n",
      "                                                'University. GLM-130B is an '\n",
      "                                                'open bilingual '\n",
      "                                                '(English&Chinese) version of '\n",
      "                                                'GLM with 130 billion '\n",
      "                                                'parameters, designed for '\n",
      "                                                'users with a single A100 or '\n",
      "                                                'V100 server23.'],\n",
      "                                        'GPT-NeoXT-Chat-Base-20B': ['https://huggingface.co/togethercomputer/GPT-NeoXT-Chat-Base-20B',\n",
      "                                                                    'An '\n",
      "                                                                    'open-source '\n",
      "                                                                    'language '\n",
      "                                                                    'model '\n",
      "                                                                    'that can '\n",
      "                                                                    'chat and '\n",
      "                                                                    'generate '\n",
      "                                                                    'images. '\n",
      "                                                                    'Created '\n",
      "                                                                    'by '\n",
      "                                                                    'EleutherAI.'],\n",
      "                                        'Gopher': ['https://arxiv.org/abs/2112.11446',\n",
      "                                                   'by DeepMind, a 280 billion '\n",
      "                                                   'parameter transformer '\n",
      "                                                   'language model called '\n",
      "                                                   'Gopher, is an '\n",
      "                                                   'autoregressive '\n",
      "                                                   'transformer-based dense '\n",
      "                                                   'LLM.'],\n",
      "                                        'LLaMA': ['https://github.com/facebookresearch/llama',\n",
      "                                                  'by Meta AI, A foundational, '\n",
      "                                                  '65-billion-parameter large '\n",
      "                                                  'language model. LLaMA '\n",
      "                                                  '(Large Language Model Meta '\n",
      "                                                  'AI) is a state-of-the-art '\n",
      "                                                  'foundational large language '\n",
      "                                                  'model designed to help '\n",
      "                                                  'researchers advance their '\n",
      "                                                  'work in this subfield of '\n",
      "                                                  'AI.'],\n",
      "                                        'LaMDA': ['https://blog.google/technology/ai/lamda/',\n",
      "                                                  'Language Model for Dialogue '\n",
      "                                                  'Applications is a family of '\n",
      "                                                  'conversational large '\n",
      "                                                  'language models developed '\n",
      "                                                  'by Google. LaMDA uses a '\n",
      "                                                  'decoder-only transformer '\n",
      "                                                  'language model.'],\n",
      "                                        'OPT': ['Not provided',\n",
      "                                                'by Meta, The OPT model was '\n",
      "                                                'proposed in Open Pre-trained '\n",
      "                                                'Transformer Language Models '\n",
      "                                                'by Meta AI. OPT is a series '\n",
      "                                                'of open-sourced large causal '\n",
      "                                                'language models which perform '\n",
      "                                                'similar in performance to '\n",
      "                                                'GPT3.']},\n",
      "                               'Meta': {'LLAMA': {'Date': '2023/02',\n",
      "                                                  'Desc': 'LLaMA 是 Meta AI '\n",
      "                                                          '发布的包含 7B、13B、33B 和 '\n",
      "                                                          '65B '\n",
      "                                                          '四种参数规模的基础语言模型集合，LLaMA-13B '\n",
      "                                                          '仅以 1/10 规模的参数在多数的 '\n",
      "                                                          'benchmarks 上性能优于 '\n",
      "                                                          'GPT-3(175B)，LLaMA-65B '\n",
      "                                                          '与业内最好的模型 '\n",
      "                                                          'Chinchilla-70B 和 '\n",
      "                                                          'PaLM-540B '\n",
      "                                                          '比较也具有竞争力。这项工作重点关注使用比通常更多的 '\n",
      "                                                          'tokens '\n",
      "                                                          '训练一系列语言模型，在不同的推理预算下实现最佳的性能，也就是说在相对较小的模型上使用大规模数据集训练并达到较好性能。Chinchilla '\n",
      "                                                          '论文中推荐在 200B 的 '\n",
      "                                                          'tokens 上训练 10B '\n",
      "                                                          '规模的模型，而 LLaMA 使用了 '\n",
      "                                                          '1.4T tokens 训练 '\n",
      "                                                          '7B的模型，增大 tokens '\n",
      "                                                          '规模，模型的性能仍在持续上升。',\n",
      "                                                  'Dev': {'LAION AI': {'OpenAssistant-Pythia': {'Date': '2023/04',\n",
      "                                                                                                'Desc': '这是Open-Assistant项目的第四次迭代英语监督微调(SFT)模型。它基于一个Pythia '\n",
      "                                                                                                        '12B模型，该模型在2023年3月25日之前通过https://open-assistant.io/人工反馈Web应用程序收集的助手对话人类演示进行了微调。',\n",
      "                                                                                                'GPU': '',\n",
      "                                                                                                'Lang': 'EN',\n",
      "                                                                                                'Links': 'https://github.com/LAION-AI/Open-Assistant',\n",
      "                                                                                                'Size': '12B'}},\n",
      "                                                          'LM-SYS': {'Vicuna': {'Date': '2023/03',\n",
      "                                                                                'Desc': '23年3.31日，受 '\n",
      "                                                                                        'Meta '\n",
      "                                                                                        'LLaMA '\n",
      "                                                                                        '和 '\n",
      "                                                                                        'Stanford '\n",
      "                                                                                        'Alpaca '\n",
      "                                                                                        '项目的启发，加州大学伯克利分校(UC '\n",
      "                                                                                        'Berkeley)等大学的研究者根据从 '\n",
      "                                                                                        'ShareGPT.com '\n",
      "                                                                                        '(ShareGPT是一个用户可以分享他们的 '\n",
      "                                                                                        'ChatGPT '\n",
      "                                                                                        '对话的网站)收集的用户共享对话微调 '\n",
      "                                                                                        'LLaMA '\n",
      "                                                                                        '推出了Vicuna-13B',\n",
      "                                                                                'Dev': {'King Abdullah University of Science and Technology': {'MiniGPT-4': {'Date': '2023/04',\n",
      "                                                                                                                                                             'Desc': 'MiniGPT-4是一个可以理解图片的大语言模型，是由开源的预训练模型Vicuna-13B与BLIP-2结合的新模型。MiniGPT-4是分两个阶段训练的。首先是使用500万个图像-文本数据训练，在4个A100上训练了10个小时左右，不过这个阶段的模型的生成能力受到了严重的影响，因此还有第二个阶段；第二个阶段是通过模型本身和ChatGPT一起创建高质量的图像文本对，这是一个小而高质量的数据集（共计3500个对）。然后在对话模板中使用这个数据集进行训练，显著提高了其生成可靠性和整体可用性；但是这个阶段的微调效率很高，一个A100在大约7分钟内就可以完成。',\n",
      "                                                                                                                                                             'GPU': '12G',\n",
      "                                                                                                                                                             'Lang': 'CH,EN',\n",
      "                                                                                                                                                             'Links': 'https://github.com/Vision-CAIR/MiniGPT-4',\n",
      "                                                                                                                                                             'Size': '7B,13B'}}},\n",
      "                                                                                'GPU': '14G',\n",
      "                                                                                'Lang': 'CH,EN',\n",
      "                                                                                'Links': 'https://github.com/lm-sys/FastChat',\n",
      "                                                                                'Size': '7B,13B'}},\n",
      "                                                          'Nomic AI': {'GPT4ALL': {'Date': '2023/03',\n",
      "                                                                                   'Desc': 'GPT4All是基于LLaMA模型70亿参数微调而成。GPT4All '\n",
      "                                                                                           '在GPT-3.5-Turbo '\n",
      "                                                                                           '的800k '\n",
      "                                                                                           '条数据上进行训练，包括文字问题、故事描述、多轮对话和代码。在答案生成方面，几乎与ChatGPT相似，但资源消耗方面更低。',\n",
      "                                                                                   'GPU': '14G',\n",
      "                                                                                   'Lang': 'EN',\n",
      "                                                                                   'Links': 'https://github.com/hpcaitech/ColossalAI',\n",
      "                                                                                   'Size': '7B'}},\n",
      "                                                          'Stability AI': {'StableLM': {'Date': '2023/04',\n",
      "                                                                                        'Desc': 'StableLM是StabilityAI开源的一个大语言模型。于2023年4月20日公布，目前属于开发中，只公布了部分版本模型训练结果。StabilityAI是著名的开源软件Stable '\n",
      "                                                                                                'Diffusion的开发者，该系列模型完全开源，但是做的是文本生成图像方向。而本次发布的StableLM是StabilityAI的第一个开源的大语言模型。该模型基于Pile数据训练，但是是一个新的Pile数据集，比原始的Pile数据集大3倍，包含约1.5万亿tokens，数据集目前没有公开，但是官方说后续在适当的时机会公布。模型训练的context长度是4096个。',\n",
      "                                                                                        'GPU': '',\n",
      "                                                                                        'Lang': 'EN',\n",
      "                                                                                        'Links': 'https://github.com/Stability-AI/StableLM',\n",
      "                                                                                        'Size': '175B'}},\n",
      "                                                          'StandFord': {'Alpaca': {'Date': '2023/03',\n",
      "                                                                                   'Desc': 'Alpaca（羊驼）模型是斯坦福大学基于 '\n",
      "                                                                                           'Meta '\n",
      "                                                                                           '开源的 '\n",
      "                                                                                           'LLaMA-7B '\n",
      "                                                                                           '模型微调得到的指令遵循（instruction-following）的语言模型。在有学术预算限制情况下，训练高质量的指令遵循模型主要面临强大的预训练语言模型和高质量的指令遵循数据两个挑战，作者利用 '\n",
      "                                                                                           'OpenAI '\n",
      "                                                                                           '的 '\n",
      "                                                                                           'text-davinci-003 '\n",
      "                                                                                           '模型以 '\n",
      "                                                                                           'self-instruct '\n",
      "                                                                                           '方式生成 '\n",
      "                                                                                           '52K '\n",
      "                                                                                           '的指令遵循样本数据，利用这些数据训练以有监督的方式训练 '\n",
      "                                                                                           'LLaMA-7B '\n",
      "                                                                                           '得到 '\n",
      "                                                                                           'Alpaca '\n",
      "                                                                                           '模型。在测试中，Alpaca '\n",
      "                                                                                           '的很多行为表现都与 '\n",
      "                                                                                           'text-davinci-003 '\n",
      "                                                                                           '类似，且只有 '\n",
      "                                                                                           '7B '\n",
      "                                                                                           '参数的轻量级模型 '\n",
      "                                                                                           'Alpaca '\n",
      "                                                                                           '性能可与 '\n",
      "                                                                                           'GPT-3.5 '\n",
      "                                                                                           '这样的超大规模语言模型性能媲美。',\n",
      "                                                                                   'Dev': {'Alpaca-LoRA': {'Date': '2023/03',\n",
      "                                                                                                           'Desc': '使用 '\n",
      "                                                                                                                   'low-rank '\n",
      "                                                                                                                   'adaptation '\n",
      "                                                                                                                   '(LoRA) '\n",
      "                                                                                                                   '重现 '\n",
      "                                                                                                                   'Alpaca '\n",
      "                                                                                                                   '的结果，并且能够以一块消费级显卡，在几小时内完成 '\n",
      "                                                                                                                   '7B '\n",
      "                                                                                                                   '模型的 '\n",
      "                                                                                                                   'fine-turning。',\n",
      "                                                                                                           'Dev': {'Japanese-Alpaca-LoRA': 'https://github.com/masa3141/japanese-alpaca-lora',\n",
      "                                                                                                                   'KoAlpaca': 'https://github.com/Beomi/KoAlpaca'},\n",
      "                                                                                                           'Lang': 'EN',\n",
      "                                                                                                           'Links': 'https://github.com/tatsu-lab/stanford_alpaca',\n",
      "                                                                                                           'Size': '7B'},\n",
      "                                                                                           'Chinese-Vicuna': {'Date': '2023/03',\n",
      "                                                                                                              'Desc': '一个中文低资源的llama+lora方案，结构参考alpaca',\n",
      "                                                                                                              'Lang': 'CH',\n",
      "                                                                                                              'Links': 'https://github.com/Facico/Chinese-Vicuna',\n",
      "                                                                                                              'Size': '7B'},\n",
      "                                                                                           'Chinese-alpaca-lora': {'Date': '2023/03',\n",
      "                                                                                                                   'Desc': '骆驼:A '\n",
      "                                                                                                                           'Chinese '\n",
      "                                                                                                                           'finetuned '\n",
      "                                                                                                                           'instruction '\n",
      "                                                                                                                           'LLaMA. '\n",
      "                                                                                                                           'Developed '\n",
      "                                                                                                                           'by '\n",
      "                                                                                                                           '陈启源 '\n",
      "                                                                                                                           '@ '\n",
      "                                                                                                                           '华中师范大学 '\n",
      "                                                                                                                           '& '\n",
      "                                                                                                                           '李鲁鲁 '\n",
      "                                                                                                                           '@ '\n",
      "                                                                                                                           '商汤科技 '\n",
      "                                                                                                                           '& '\n",
      "                                                                                                                           '冷子昂 '\n",
      "                                                                                                                           '@ '\n",
      "                                                                                                                           '商汤科技',\n",
      "                                                                                                                   'Lang': 'CH',\n",
      "                                                                                                                   'Links': 'https://github.com/LC1332/Chinese-alpaca-lora',\n",
      "                                                                                                                   'Size': '7B'}},\n",
      "                                                                                   'Lang': 'Multi',\n",
      "                                                                                   'Links': 'https://github.com/tatsu-lab/stanford_alpaca',\n",
      "                                                                                   'Size': '7B'}},\n",
      "                                                          'Yiming Cui, Ziqing Yang, Xin Yao': {'Chinese LLaMA': {'Date': '2023/03',\n",
      "                                                                                                                 'Desc': 'Chinese '\n",
      "                                                                                                                         'LLaMA(也称中文LLaMA，有7B和13B两个版本，项目地址)，相当于在原版LLaMA的基础上扩充了中文词表并使用了中文数据进行二次预训练，进一步提升了中文基础语义理解能力，同时，在中文LLaMA的基础上，且用中文指令数据进行指令精调得Chinese-Alpaca(也称中文Alpaca，同样也有7B和13B两个版本)',\n",
      "                                                                                                                 'Lang': 'Multi',\n",
      "                                                                                                                 'Links': 'https://github.com/ymcui/Chinese-LLaMA-Alpaca',\n",
      "                                                                                                                 'Size': '7B-65B'}},\n",
      "                                                          '潞晨科技': {'ColossalAI': {'Date': '2023/03',\n",
      "                                                                                  'Desc': 'Colossal-AI作为ChatGPT的平替，开源了完整的RLHF流水线，包括，监督数据收集、监督微调、奖励模型训练和强化学习微调等。基于LLaMA预训练模型，并分享最实用的开源项目ColossalChat。ColossalChat只用了不到100亿参数就达到中英文双语能力，通过在大语言模型基础上的RLHF微调，实现了与ChatGPT和GPT-3.5类似的效果。',\n",
      "                                                                                  'GPU': '4G',\n",
      "                                                                                  'Lang': 'CH,EN',\n",
      "                                                                                  'Links': 'https://github.com/hpcaitech/ColossalAI',\n",
      "                                                                                  'Size': '7B'}},\n",
      "                                                          '链家科技': {'BELLE': {'Date': '2023/03',\n",
      "                                                                             'Desc': '开源中文对话大模型,结合中文语料通过Self '\n",
      "                                                                                     'Instruct方式微调BLOOMZ-7B或LLaMA',\n",
      "                                                                             'Lang': 'Multi',\n",
      "                                                                             'Links': 'https://github.com/LianjiaTech/BELLE',\n",
      "                                                                             'Size': '7B-65B'}}},\n",
      "                                                  'Lang': 'Multi',\n",
      "                                                  'Links': 'https://github.com/facebookresearch/llama',\n",
      "                                                  'Size': '7B-65B'},\n",
      "                                        'OPT': {'Date': '2022/05',\n",
      "                                                'Desc': '由 Meta AI '\n",
      "                                                        '研究人员发布的一系列大规模预训练语言模型，模型包括125M、350M、1.3B、2.7B、6.7B、13B、30B、66B、175B '\n",
      "                                                        '9个不同的参数规模和版本，除了 175B '\n",
      "                                                        '的版本需要填写申请获取外，其它规模版本的模型都完全开放下载，可以免费获得。OPT-175B '\n",
      "                                                        '和 GPT-3 '\n",
      "                                                        '的性能相当，并且部署只需要损耗 GPT-3 '\n",
      "                                                        '1/7 的能量损耗。OPT '\n",
      "                                                        '系列模型开源的目的是为促进学术研究和交流，因为绝大多数大语言模型训练成本高昂，导致大部分研究人员都无法负担大语言模型的训练或使用；同时，各大企业发布的大语言预训练模型由于商业目的也都无法完整访问模型权重，只能通过 '\n",
      "                                                        'API '\n",
      "                                                        '调用获取结果，阻碍了学术的交流与研究。',\n",
      "                                                'Dev': {},\n",
      "                                                'Lang': 'EN',\n",
      "                                                'Links': 'https://github.com/facebookresearch/metaseq',\n",
      "                                                'Size': '125B-175B'}},\n",
      "                               'Tsinghua': {'GLM-130B': {'Date': '2022/08',\n",
      "                                                         'Desc': 'GLM-130B '\n",
      "                                                                 '是一个开放的双语（英汉）双向密集模型，具有 '\n",
      "                                                                 '1300 '\n",
      "                                                                 '亿个参数，使用通用语言模型（GLM）的算法进行预训练。它旨在支持单台A100（40G '\n",
      "                                                                 '* '\n",
      "                                                                 '8）或V100（32G '\n",
      "                                                                 '* '\n",
      "                                                                 '8）服务器上具有130B参数的推理任务。通过 '\n",
      "                                                                 'INT4 '\n",
      "                                                                 '量化，硬件要求可以进一步降低到具有 '\n",
      "                                                                 '4 * RTX '\n",
      "                                                                 '3090（24G）的单个服务器，而性能几乎没有下降。截至 '\n",
      "                                                                 '2022 年 7 月 3 '\n",
      "                                                                 '日，GLM-130B '\n",
      "                                                                 '已经接受了超过 4000 '\n",
      "                                                                 '亿个文本标记（中文和英文各 '\n",
      "                                                                 '200B）的训练',\n",
      "                                                         'Dev': {'Tsinghua': {'ChatGLM-6B': {'Date': '2023/03',\n",
      "                                                                                             'Desc': '62 '\n",
      "                                                                                                     '亿参数的 '\n",
      "                                                                                                     'ChatGLM-6B，结合模型量化技术，用户可以在消费级的显卡上进行本地部署（INT4 '\n",
      "                                                                                                     '量化级别下最低只需 '\n",
      "                                                                                                     '6GB '\n",
      "                                                                                                     '显存），虽然规模不及千亿模型，但大大降低了用户部署的门槛，并且已经能生成相当符合人类偏好的回答',\n",
      "                                                                                             'GPU': '6G',\n",
      "                                                                                             'Lang': 'EN,CN',\n",
      "                                                                                             'Links': 'https://github.com/THUDM/ChatGLM-6B',\n",
      "                                                                                             'Size': '6B'}}},\n",
      "                                                         'Lang': 'EN,CN',\n",
      "                                                         'Links': 'https://github.com/facebookresearch/llama',\n",
      "                                                         'Size': '130B'}}},\n",
      "                      '资源拓展': {'ChatGPT 中文指南，ChatGPT 中文调教指南，指令指南，精选资源清单，更好的使用 ChatGPT 让你的生产力飙升！': 'https://github.com/yzfly/awesome-chatgpt-zh',\n",
      "                               'ChatGPT 网址导航，分享免费好用 AI 网站！': 'https://github.com/LangLangShanDeNanKe/chatgpt',\n",
      "                               'ChatGPT 资料汇总学习，持续更新......': 'https://github.com/dalinvip/Awesome-ChatGPT',\n",
      "                               '⚡ 关于 ChatGPT 的一切': 'https://github.com/OpenMindClub/awesome-chatgpt',\n",
      "                               '免费的ChatGPT站点列表，为你准备了众多免费好用的ChatGPT镜像站点，当前100+站点': 'https://github.com/xx025/carrot',\n",
      "                               '完全开放的ChatGPT替代方案列表': 'https://github.com/nichtdax/awesome-totally-open-chatgpt',\n",
      "                               '搜集国内可用的ChatGPT在线体验免费网站列表。定时任务每日更新': 'https://github.com/lzwme/chatgpt-sites',\n",
      "                               '精选 ChatGPT 和 GPT-3 相关的出色工具、演示、文档的列表': 'https://github.com/humanloop/awesome-chatgpt',\n",
      "                               '精选的应用程序和工具列表，这些应用程序和工具不仅使用新的 ChatGPT API，而且允许用户配置自己的 API...': 'https://github.com/reorx/awesome-chatgpt-api',\n",
      "                               '🆓免费的ChatGPT镜像网站列表，持续更新。持续更新的免费ChatGPT镜像站点列表': 'https://github.com/LiLittleCat/awesome-free-chatgpt',\n",
      "                               '🧠 精选的ChatGPT资源列表，包括库、SDK、API等。🌟 请考虑支持这些项目！': 'https://github.com/eon01/awesome-chatgpt'}},\n",
      "             '参考': {'类ChatGPT的部署与微调(上)：从TRL到LLaMA、Alpaca/Vicuna/BELLE、中文版': 'https://blog.csdn.net/v_JULY_v/article/details/129709105'},\n",
      "             '基础了解': {'博客': 'https://openai.com/blog/chatgpt/',\n",
      "                      '提示词相关': {'提示示例': {'中文': 'https://github.com/PlexPt/awesome-chatgpt-prompts-zh',\n",
      "                                         '英文': 'https://github.com/f/awesome-chatgpt-prompts'},\n",
      "                                '提示词买卖': {'Opengpt': 'https://open-gpt.app/',\n",
      "                                          'PromptBase 是买卖优质提示的市场': 'https://promptbase.com/'},\n",
      "                                '提示词学习': {'500 个对作家有帮助的提示': 'https://github.com/OpenMindClub/awesome-chatgpt',\n",
      "                                          'ChatGPT Shortcut': 'https://www.aishort.top/',\n",
      "                                          'Jrnylist (关键词参考)': 'https://www.jrnylist.com/',\n",
      "                                          'Noonshot (生成Midjourney关键词)': 'https://prompt.noonshot.com/',\n",
      "                                          'OpenAI的工作人员告诉你如何给GPT清晰有效的指令。': 'https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api',\n",
      "                                          'Prompt 编写模式：如何将思维框架赋予机器，以设计模式的形式来思考 prompt': 'https://github.com/prompt-engineering/prompt-patterns',\n",
      "                                          'PromptDB': 'https://promptdb.ai/',\n",
      "                                          '提示工程的指南': 'https://github.com/dair-ai/Prompt-Engineering-Guide'},\n",
      "                                '提示词效率提升': {'最大限度地提高您的效率和生产力。让生产力加倍的ChatGPT 快速指令，点击领域和功能分区，可对提示词进行标签筛选、关键词搜索和一键复制。': 'https://github.com/rockbenben/ChatGPT-Shortcut'},\n",
      "                                '提示词破解': {'ChatGPT DAN，破解提示': 'https://github.com/0xk1h0/ChatGPT_DAN'}},\n",
      "                      '文档': 'https://beta.openai.com/docs',\n",
      "                      '维基百科': 'https://en.wikipedia.org/w/index.php?title=ChatGPT'},\n",
      "             '我的实现': {},\n",
      "             '投资人': {'Corporate Round': ['Microsoft'],\n",
      "                     'Pre Seed Round': ['Y Combinator'],\n",
      "                     'Second Market': ['Tiger Global Management',\n",
      "                                       'Andreessen Horowitz',\n",
      "                                       'Sequoia Capital',\n",
      "                                       'Bedrock Capital',\n",
      "                                       'Matthew Brown Companies'],\n",
      "                     'Seed Round': ['Reid Hoffman Foundation',\n",
      "                                    'Khosla Ventures']},\n",
      "             '替代产品': {},\n",
      "             '相关产品': {'代码类': {'cursor (GPT4.0)': 'https://www.cursor.so/'},\n",
      "                      '同类产品': {'ChatGPT克隆': {'BAI Chat': 'https://chat.theb.ai/',\n",
      "                                             'Chat For AI': 'https://chatforai.com/',\n",
      "                                             'Fast GPT': 'https://fastgpt.app/',\n",
      "                                             'FreeGPT': 'https://freegpt.one/'},\n",
      "                               '合作产品': {'Microsoft 365 Copilot': 'https://blogs.microsoft.com/blog/2023/03/16/introducing-microsoft-365-copilot-your-copilot-for-work/',\n",
      "                                        'New Bing': 'https://www.bing.com/new',\n",
      "                                        'Notion': 'https://www.notion.so/',\n",
      "                                        'Virtuzone': 'https://launchpad.vz.ae/'}},\n",
      "                      '帮你写': {'AI Screenwriter': 'https://aiscreenwriter.com/',\n",
      "                              'Ai Mailer': 'https://ai-mailer.com/',\n",
      "                              'Chatsonic': 'https://writesonic.com/chat',\n",
      "                              'Craft': 'https://www.craft.do/',\n",
      "                              'Easy-Peasy.AI': 'http://easy-peasy.ai/',\n",
      "                              'HoppyCopy': 'https://www.hoppycopy.co/',\n",
      "                              'Jasper': 'https://www.jasper.ai/',\n",
      "                              'MagickPen': 'https://magickpen.com/',\n",
      "                              'MarketingBlocks': 'https://hey.marketingblocks.ai/',\n",
      "                              'Peppertype': 'https://www.peppertype.ai/',\n",
      "                              'Poe (GPT4.0)': 'https://poe.com/',\n",
      "                              'Rytr': 'https://rytr.me/',\n",
      "                              'SEO GPT': 'https://seovendor.co/',\n",
      "                              'Shakespeare': 'https://www.shakespeare.ai/',\n",
      "                              'TypeAI': 'https://type.ai/',\n",
      "                              'Vondy': 'https://www.vondy.com/',\n",
      "                              'Yaara': 'https://yaara.ai/',\n",
      "                              'Yarnit': 'https://www.yarnit.app/',\n",
      "                              'copyai': 'https://www.copy.ai/',\n",
      "                              'copymatic': 'https://copymatic.ai/',\n",
      "                              '写作猫': 'https://xiezuocat.com/'},\n",
      "                      '帮你回': {'ChatWP': 'https://wpdocs.chat/',\n",
      "                              'Mottle': 'https://mottle.com/'},\n",
      "                      '帮你定': {'佛前AI': 'https://hotoke.ai/',\n",
      "                              '决策Rationale': 'https://rationale.jinaai.cn/'},\n",
      "                      '帮你想': {'ChatMind': 'https://www.chatmind.tech/'},\n",
      "                      '帮你画': {'Hypotenuse AI (文字内容和绘画)': 'https://app.hypotenuse.ai/invited',\n",
      "                              'Prompt Hunt (DALL·E和Midjourney绘画)': 'https://www.prompthunt.com/',\n",
      "                              'PromptBase (DALL·E,Midjourney,ChatGPT,Stable Diffusion绘画)': 'https://promptbase.com/'},\n",
      "                      '帮你看': {'BiliGPT': 'https://b.jimmylv.cn/',\n",
      "                              'ClipRecaps': 'https://cliprecaps.com/',\n",
      "                              'SolidPoint': 'https://www.solidpoint.ai/',\n",
      "                              'summarize.tech': 'https://www.summarize.tech/',\n",
      "                              '新闻摘要Artifact': 'https://artifact.news/'},\n",
      "                      '帮你读': {'ChatExcel': 'https://chatexcel.com/convert',\n",
      "                              'ChatPDF': 'https://www.chatpdf.com/',\n",
      "                              'Excelformulabot': 'https://excelformulabot.com/',\n",
      "                              'Explainpaper': 'https://www.explainpaper.com/',\n",
      "                              'Humata': 'https://www.humata.ai/',\n",
      "                              'LATERAL': 'https://www.lateral.io/',\n",
      "                              'PandaGPT': 'https://pandagpt.io/',\n",
      "                              'SCISPACE': 'https://typeset.io/',\n",
      "                              'arXiv Xplorer': 'https://arxivxplorer.com/',\n",
      "                              '聊天简化器': 'https://chat-simplifier.imzbb.cc/zh',\n",
      "                              '风声雨声': 'https://fsys.app/'},\n",
      "                      '平台嵌入': {'Drafts': {'ChatGPTConversation': 'https://directory.getdrafts.com/a/2HJ'},\n",
      "                               'Github': {'CR.GPT': 'https://github.com/apps/cr-gpt'},\n",
      "                               'IPhone': {'AssisChat': 'https://apps.apple.com/us/app/assischat/id6446092669',\n",
      "                                          'OpenCat': 'https://opencat.app/',\n",
      "                                          'OpenKit': 'https://apps.apple.com/cn/app/openchit/id6446192123'},\n",
      "                               'Mac': {'MacGPT': 'https://www.macgpt.com/',\n",
      "                                       'My Six ChatGPT Assistants': 'https://pinchlime.com/newsletters/my-six-chatgpt-assistants/',\n",
      "                                       '划词工具PopClip Extensions': 'https://pilotmoon.com/popclip/extensions/page/ChatGPT',\n",
      "                                       '键盘快捷键选择和复制文本以向ChatGPT提问。': 'https://blog.retompi.com/post/use-chatgpt-api/#keyboard-maestro'},\n",
      "                               'Siri': {'Siri Pro': 'https://www.icloud.com/shortcuts/6889d862918e479693be11fd9a0293b2'},\n",
      "                               '浏览器插件': {'42share': 'https://42share.io/',\n",
      "                                         'AIPRM for ChatGPT': 'www.aiprm.com',\n",
      "                                         'ArxivGPT': 'https://chrome.google.com/webstore/detail/arxivgpt/fbbfpcjhnnklhmncjickdipdlhoddjoh?hl=en',\n",
      "                                         'ChatGPT Sidebar': 'https://chatgpt-sidebar.com/',\n",
      "                                         'ChatGPT for Google': 'https://chrome.google.com/webstore/detail/chatgpt-for-google/jgjaeacdkonaoafenlfkkkmbaopkbilf',\n",
      "                                         'ChatGPT 智能提示': 'https://chrome.google.com/webstore/detail/chatgpt-prompt-genius/jjdnakkfjnnbbckhifcfchagnpofjffo',\n",
      "                                         'ChatGPTwriter': 'https://chatgptwriter.ai/',\n",
      "                                         'ChatHub': 'https://chrome.google.com/webstore/detail/chathub-all-in-one-chatbo/iaakpnchhognanibcahlpcplchdfmgma',\n",
      "                                         'Detect GPT': 'https://www.thomas.io/detect-gpt',\n",
      "                                         'Fluentify': 'https://www.fluentify.io/',\n",
      "                                         'Glarity': 'https://glarity.app/',\n",
      "                                         'HARPA AI': 'https://harpa.ai/',\n",
      "                                         'ShareGPT': 'https://sharegpt.com/',\n",
      "                                         'TeamSmart AI': 'https://www.teamsmart.ai/',\n",
      "                                         '网站和 YouTube 视频摘要': 'https://chrome.google.com/webstore/detail/chatgpt-%C2%BB-summarize-every/cbgecfllfhmmnknmamkejadjmnmpfjmp'}},\n",
      "                      '搜索引擎': {'Perplexity AI': 'https://www.perplexity.ai/',\n",
      "                               'YouGPT': 'https://you.com/'},\n",
      "                      '竞争产品': {'Poe': 'https://quorablog.quora.com/Poe-1',\n",
      "                               '百度文心一言': 'https://yige.baidu.com/'}},\n",
      "             '相关内容': {'汉语': {'文本': {'ChatGPT 商务速成 - 中译版': 'https://www.notion.so/8ce48bcb5aa94828a64c86a2dbfc307d',\n",
      "                                    'ChatGPT 终极指南 - 中译版': 'https://geekr.dev/posts/chatgpt-ultimate-guide',\n",
      "                                    '如何使用 Python 快速集成 ChatGPT API': 'https://mp.weixin.qq.com/s?__biz=MjM5MjU2NDk0Nw==&mid=2247507931&idx=2&sn=77f75026c365b73275f7ce3f2e7d0ab4&chksm=a6a6cc6791d14571df77a1a5c249bc46ffd03269b264aadbdfa43927e809b578d501a1c58f31&mpshare=1&scene=1&srcid=0308V8ZG15g6BE1TgRXPEWYa&sharer_sharetime=1678253425412&sharer_shareid=a697a75b41763c317bec849da7e5a35a#rd',\n",
      "                                    '如何用 ChatGPT 构建你的专属知识问答机器人': 'https://blog.frankzhao.cn/build_gpt_bot_for_doc/',\n",
      "                                    '拆解追溯 GPT-3.5 各项能力的起源 - 中译版': 'https://www.notion.so/360081d91ec245f29029d37b54573756',\n",
      "                                    '理解大语言模型——10 篇论文的简明清单': 'https://mp.weixin.qq.com/s/h7Pam1mepgd18aeqn7_3hw',\n",
      "                                    '追赶ChatGPT的难点与平替': 'https://mp.weixin.qq.com/s/eYmssaPFODjC7xwh1jHydQ'},\n",
      "                             '音视频': {'ChatGPT 保姆级使用教程：注册、体验、底层逻辑原理解读！': 'https://www.bilibili.com/video/BV1HT411R7Lj/',\n",
      "                                     '【渐构】万字科普ChatGPT-4为什么会颠覆人类社会': 'https://www.bilibili.com/video/BV1MY4y1R7EN/?spm_id_from=333.880.my_history.page.click&vd_source=6faef52e732ccc3a4a525fe406ce9808'}},\n",
      "                      '英语': {'文本': {'Full ChatGPT Prompts + Resources': 'https://www.notion.so/8aa78bb226b7467ab59b70d2b27042e9',\n",
      "                                    'How does GPT Obtain its Ability? Tracing Emergent Abilities of Language Models to their Sources - 有中译版': 'https://www.notion.so/b9a57ac0fcf74f30a1ab9e3e36fa1dc1',\n",
      "                                    'How to use ChatGPT APIs in Python': 'https://medium.com/@FrancescoZ/how-to-use-chatgpt-with-python-e7a8868e6034',\n",
      "                                    'The-Ultimate-ChatGPT-Guide': 'https://www.notion.so/8800517adc0d4c569d4a317c177185a1'},\n",
      "                             '音视频': {'Advanced ChatGPT: Full Guide:': 'https://www.notion.so/ac6aa68840bc427c83f4611dd2642f83',\n",
      "                                     'ChatGPT 101: Learn ChatGPT Prompts & ChatGPT Smart Tips': 'https://www.udemy.com/course/trend-spotter/',\n",
      "                                     'ChatGPT Masterclass - Build Solutions and Apps with ChatGPT': 'https://www.udemy.com/course/chatgpt-build-solutions-and-apps-with-chatgpt-and-openai/',\n",
      "                                     'ChatGPT Masterclass: A Complete ChatGPT Guide for Beginners': 'https://www.udemy.com/course/chatgpt-masterclass-a-complete-chatgpt-guide-for-beginners/',\n",
      "                                     'ChatGPT Masterclass: Smart Tips & ChatGPT Insights & Future': 'https://www.udemy.com/course/chatgpt-masterclass-smart-tips-insights/',\n",
      "                                     'ChatGPT Tutorial - A Crash Course on Chat GPT for Beginners:': 'https://www.youtube.com/watch?v=JTxsNm9IdYU',\n",
      "                                     'ChatGPT Tutorial for Developers - 38 Ways to 10x Your Productivity:': 'https://www.youtube.com/watch?v=sTeoEFzVNSc',\n",
      "                                     'ChatGPT for Programmers: Build Python Apps in Seconds': 'https://www.udemy.com/course/chatgpt-for-programmers/',\n",
      "                                     'ChatGPT: Complete ChatGPT Course For Work 2023 (Ethically)': 'https://www.udemy.com/course/chatgpt-complete-chatgpt-course-for-work-2023-ethically-chat-gpt/',\n",
      "                                     'Complete ChatGPT Tutorial - [Become A Power User in 30 Minutes]': 'https://www.youtube.com/watch?v=jHv63Uvk5VA',\n",
      "                                     'More Courses: Udemy → ChatGPT': 'https://www.udemy.com/courses/search/?src=ukw&q=ChatGPT',\n",
      "                                     'The Ultimate Chat GPT Course': 'https://www.notion.so/69ed24a317a942d288e740419b1ad6f6'}}},\n",
      "             '社交媒体': {'OpenAI Discord': 'https://discord.com/invite/openai',\n",
      "                      'OpenAI GitHub': 'https://github.com/openai',\n",
      "                      'OpenAI LinkedIn': 'https://www.linkedin.com/company/openai',\n",
      "                      'OpenAI SoundCloud': 'https://soundcloud.com/openai_audio',\n",
      "                      'OpenAI Twitter': 'https://twitter.com/openai',\n",
      "                      'OpenAI YouTube': 'https://www.youtube.com/OpenAI'},\n",
      "             '风险投资': {'Ambience Healthcare': 'https://www.ambiencehealthcare.com/',\n",
      "                      'Descript': 'https://www.descript.com/',\n",
      "                      'Harvey': 'https://www.harvey.ai/',\n",
      "                      'Mem': 'https://get.mem.ai/',\n",
      "                      'Speak': 'https://www.speak.com/',\n",
      "                      'edgedb': 'https://www.edgedb.com/'}}}\n"
     ]
    }
   ],
   "source": [
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da907723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2c53538",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m texts \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39msplit_documents(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python3_11/lib/python3.11/site-packages/langchain/text_splitter.py:65\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: List[Document]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124;03m\"\"\"Split documents.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m     66\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/python3_11/lib/python3.11/site-packages/langchain/text_splitter.py:65\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, documents: List[Document]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;124;03m\"\"\"Split documents.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m     66\u001b[0m     metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_documents(texts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82776c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741728f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386f6588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
